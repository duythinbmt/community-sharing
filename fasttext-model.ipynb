{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "# Product Review Analysis - FastText Supervised Model Accuracy 91.7%\r\n",
    "## One of the fastest and most accessible text classifier to anyone, without GPU\r\n",
    "FastText is well known for its distributed representation, which ultimately gets used as an embedding layer in a typical Deep Learning model such as a CNN or an LSTM. However, many don't know that FastText is also a supervised model. To prove the point, this Amazon dataset has been created to support the FastText format. And yet, 6 months later, no one has even tried to post a kernel for using FastText supervised model. What many also don't know is that, it is in fact a pretty good supervised model. Probably one of the fastest and the best out there without using a GPU. I'll cut straight to the chase and demonstrate how this is done. For a full writeup that's about to come soon, check out my blog post here:\r\n",
    "<br/> https://mungingdata.wordpress.com/\r\n",
    "\r\n",
    "Also, a very accessible paper that introduces the viability of the FastText supervised model from the original authors [here](https://arxiv.org/pdf/1607.01759.pdf)\r\n",
    "\r\n",
    "Ok so, lets begin. Its going to be fast trust me"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np # linear algebra\r\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
    "import fasttext\r\n",
    "import bz2\r\n",
    "import csv\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "import os\r\n",
    "print(os.listdir(\"../data\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['amazon-reviews', 'glove', 'glove-twitter-27B-100d.txt', 'imdb-dataset.csv', 'reviews.csv']\n"
     ]
    }
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the training data \r\n",
    "data = bz2.BZ2File(\"../data/amazon-reviews/train.ft.txt.bz2\")\r\n",
    "data = data.readlines()\r\n",
    "data = [x.decode('utf-8') for x in data]\r\n",
    "print(len(data)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3600000\n"
     ]
    }
   ],
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 3.6mil rows! Lets inspect a few records to see the format and get a feel for the data\r\n",
    "data[1:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
       " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data prep and modelling\n",
    "A slight inconvenience with the FastText model is the need to save the dataset into a text file. And the annoying encoding of the \"____label__ ____#__\". Basically, the target and the text is all in the same cell. They are distinguished by the prefix of '____label__ ____#__'. Lets say if have 2 labels and one is 'Ham' and the other 'Spam', then your labels would be '____label__ ____Ham__' and '____label__ ____Spam__'. You can include as many labels as well, not just 2.   \n",
    "\n",
    "Thankfully, this dataset has already been formated in that way as you can see from the first 5 records I printed out. We just need to write it out to disk. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Data Prep\r\n",
    "data = pd.DataFrame(data)\r\n",
    "data.to_csv(\"train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\r\n",
    "\r\n",
    "# Modelling\r\n",
    "# This routine takes about 5 to 10 minutes \r\n",
    "model = fasttext.train_supervised('train.txt',label_prefix='__label__', thread=4, epoch = 10)\r\n",
    "print(model.labels, 'are the labels or targets the model is predicting')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['__label__2', '__label__1'] are the labels or targets the model is predicting\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply predictions\n",
    "Ok after about 10 minutes or so, the model is finished. Now lets apply the predictions to the test dataset. Thankfully, we don't have to write out a physical text file to do the prediction. You could if you want to, but I'm just going to use the data object"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Load the test data \r\n",
    "test = bz2.BZ2File(\"../data/amazon-reviews/test.ft.txt.bz2\")\r\n",
    "test = test.readlines()\r\n",
    "test = [x.decode('utf-8') for x in test]\r\n",
    "print(len(test), 'number of records in the test set') \r\n",
    "\r\n",
    "# To run the predict function, we need to remove the __label__1 and __label__2 from the testset.  \r\n",
    "new = [w.replace('__label__2 ', '') for w in test]\r\n",
    "new = [w.replace('__label__1 ', '') for w in new]\r\n",
    "new = [w.replace('\\n', '') for w in new]\r\n",
    "\r\n",
    "# Use the predict function \r\n",
    "pred = model.predict(new)\r\n",
    "\r\n",
    "# check the first record outputs\r\n",
    "print(pred[0][0], 'is the predicted label')\r\n",
    "print(pred[0][1], 'is the probability score')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "400000 number of records in the test set\n",
      "['__label__2'] is the predicted label\n",
      "['__label__2'] is the probability score\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation \n",
    "Ok so we have our predictions, now lets measure how well we have done? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \r\n",
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\r\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]\r\n",
    "\r\n",
    "# run the accuracy measure. \r\n",
    "print(roc_auc_score(labels, pred_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9173100000000001\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 91.7%\r\n",
    "91.7% absolute accuracy score with only just a few lines of code. Running the evaluation metric using the Probability score would yeild even higher scores but I wanted to keep it inline with the rest of the kernels so its a fair comparison. The most popular Kernel here is the CuDNNLSTM which yielded 93.7%\r\n",
    "\r\n",
    "Perhaps the most challenging bit about using FastText is just the slightly annoying data preparation step to encode the '__labels__'. Just like any data science projects, data prep is the hard yard. Otherwise, rest is pretty straight foward. I'll post another kernel on a different dataset in future and run through the processing steps to get the dataset into the correct format. And some other model tuning process."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "27c8280a805424fe1487d86b467299993bca489a9d207f36d28011e5bcf9447b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}